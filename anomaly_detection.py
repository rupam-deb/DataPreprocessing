# -*- coding: utf-8 -*-
"""Copy of Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PG8g1aQkoD-3-fON584q3V9szBOJDk3P
"""

'''
@Task Three: Additional Task - Anomaly detection
@Written By: Rupam Deb
@Platform: Python GoogleCoLab
'''

# IMPORT REQUIRED LIBRARY
import os
import pandas as pd
import numpy as np
import datetime
from datetime import timedelta
from datetime import timezone
import csv
from matplotlib import pyplot as plt
import math  
from math import pow

# MOVING AVERAGE
def moving_average(x, w):
    ma = np.convolve(x, np.ones(w), mode='valid') / w
    return np.concatenate([np.zeros(w-1)*np.nan, ma])
  
# ROLLING STANDARD DEVIATION
def moving_standard_deviation(x, w):
    # Rolling standard deviation.
    shape = x.shape[:-1] + (x.shape[-1] - w + 1, w)
    strides = x.strides + (x.strides[-1],)
    sd = np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)
    # CALL CONVOLVE FUNCTION as the Algorithm calculates mean from the convolve function
    std_mean = np.convolve(x, np.ones(w), mode='valid') / w
    
    # CALCULATE STANDDARD DEVIATION
    sd_data = []
    for i in range(len(sd)):
      value_first = 0
      value_second = 0
      # This inner for loop can be further optimized  by performing some vector multiplication
      for k in range(w):
        value_first = value_first + pow((sd[i][k] - std_mean[i]),2)
      value_second = math.sqrt(value_first/w)
      sd_data.append(value_second)
    # Behaviour similarly to the `moving_average` function.
    return np.concatenate([np.zeros(w-1)*np.nan, sd_data])

  
# MAIN ANOMALY DETECTION FUNCTION
def detect_anomalies(time, signal1, signal2, base_window, test_window):
  # check that inputs have the same shape
  if (time.shape == signal1.shape == signal2.shape):
    # check that input is long enough for the base window stats
    if (len(time) > base_window):
      # calculate a simple feature from the 2 signals
      feature = signal1 - signal2
      # calculate a mean shift score from the data
      mean_shift = np.zeros(time.shape)
      # CALL MOVING AVERAGE for BASE sliding
      base_mean = moving_average(feature, base_window)
      # CALL MOVING AVERAGE FOR TESTING sliding
      test_mean = moving_average(feature, test_window)
      #CALL ROLLING STANDARD DEVIATION
      base_std = moving_standard_deviation(feature, base_window)
    
      # CATCH Runtime Warning: divide by zero encountered in true_divide at Standard Deviation
      nan = float('nan')
      for j in range(1464):
        if(base_std[j] == 0):
          base_std[j] = nan
        
      mean_shift = (test_mean - base_mean)/base_std
      
      # PREPARE WRITER
      corpus_write = os.path.join("/content/gdrive/My Drive/data", "weather_BOM_OTHER DATA.csv")
      myData = mean_shift
      myFile = open(corpus_write, 'a')
      with myFile:
        writer = csv.writer(myFile)
        writer.writerow(myData)
        
      
      anomalies = []      
      # Generate a list of times where the mean_shift is greater than or less than 1.0
      for j in range(1464):
        #if((mean_shift[j] > 1) or (mean_shift[j] < 1)):
        if((mean_shift[j] == 1)):
          anomalies.append(time[j]) 

      return {
        'feature': feature,
        'mean_shift': mean_shift,
        'anomalies': np.array(anomalies),
      }
      
    else:
      print('Argument arrays are not long enough')
      
  else:
    print('The shapes of three fields (date, BOM data, and Weather Station data) are not same')

# MOUNT DRIVE
from google.colab import drive
drive.mount('/content/gdrive')
corpus = os.path.join("/content/gdrive/My Drive/data", "weather_BOM.csv")
# READ FILE
df = pd.read_csv(corpus)
# CONVERT INPUTS to NUMPY ARRAY
time = np.array(df['date'])
signal1 = np.array(df['BOM Data'])
signal2 = np.array(df['Weather Station Data'])   
Data = detect_anomalies(time, signal1, signal2, base_window=10, test_window=3)